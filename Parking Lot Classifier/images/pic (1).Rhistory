X=cbind(as.matrix(data[1:100,-ncol(data)]),matrix(1,nrow=100,ncol=1))
y=rbind(matrix(0,nrow=50,ncol=1),matrix(1,nrow=50,ncol=1))
tau=0.01
w=matrix(0,nrow=ncol(X),ncol=1)
plot(x <- seq(-10, 10, length.out = 10^3),y=h(a,b,x),type='l',col='black', xlim=c(-10, 10), ylim=c(-0.3, 1.3))
lines(x=seq(0, 0, length.out = 10^3),y=seq(-2, 2, length.out = 10^3))
symbols(t[1:50],y[1:50], circles=matrix(1,nrow=nrow(t)/2,ncol=1), inches=0.03, ann=F, bg="salmon", fg=NULL,  add=TRUE)
symbols(t[51:100],y[51:100], circles=matrix(1,nrow=nrow(t)/2,ncol=1), inches=0.03, ann=F, bg="lightskyblue", fg=NULL,  add=TRUE)
plot(x <- seq(-10, 10, length.out = 10^3),y=h(a,b,x),type='l',col='black', xlim=c(-10, 10), ylim=c(-0.3, 1.3))
lines(x=seq(0, 0, length.out = 10^3),y=seq(-2, 2, length.out = 10^3))
symbols(t[1:50],y[1:50], circles=matrix(1,nrow=nrow(t)/2,ncol=1), inches=0.03, ann=F, bg="salmon", fg=NULL,  add=TRUE)
symbols(t[51:100],y[51:100], circles=matrix(1,nrow=nrow(t)/2,ncol=1), inches=0.03, ann=F, bg="lightskyblue", fg=NULL,  add=TRUE)
print(a)
print(b)
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegression.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegression.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegression.R')
rm(list=ls());
h <- function(w,t){
return (1/(1+(exp(-(t(w)%*%t)))))
}
data=read.table('iris.data',sep=',')
X=cbind(as.matrix(data[1:100,-ncol(data)]),matrix(1,nrow=100,ncol=1))
y=rbind(matrix(0,nrow=50,ncol=1),matrix(1,nrow=50,ncol=1))
tau=0.01
i=0;
#Training
w=matrix(0,nrow=ncol(X),ncol=1)
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegression.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegression.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegression.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
print(h(w,X[1,]))
print(h(w,X[51,]))
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/LogisticRegressionM.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/hw2-2/HW2-2.R')
setwd('./hw2-2/')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/hw2-2/HW2-2.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/hw2-2/HW2-2_example1.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/hw2-2/HW2-2_example1.R')
source('~/Google Drive/dkim/3.Teachings/5.2016_Spring/CSCI4352/website/hw2-2/HW2-2_example2.R')
source('C:/Users/changik/Desktop/hw2-2/HW2-2_example1.R')
rm(list=ls())
col2gry <- function(img) { #720*1280
new_img = matrix(0,nrow=dim(img)[1],ncol=dim(img)[2])
for(i in 1:dim(img)[1]) {
for(j in 1:dim(img)[2]){
new_img[i,j]=sum(img[i,j,])/3
}
}
return (new_img)
}
subImage<-function(img,x1,y1,x2,y2) {
return (img[y2:y1,x1:x2])
}
library(jpeg)
plot(1:2,xlab='',ylab='',type='n', axes=FALSE, )
fs=list.files('.',pattern = '*.jpg')
fs
plot(1:2,xlab='',ylab='',type='n', axes=FALSE, )
for(i in 1:length(fs)){
j = floor((i-1)/10)
img = readJPEG(fs[i],native=FALSE)
gry=col2gry(img)
lot = subImage(gry,720,480,765,420) # location of selected lot
rasterImage(lot,  (1+0.1*((i-1)%%10))  ,2-((j+1)*0.1), (1+0.1*(((i-1)%%10)+1)) ,2-(j*0.1))
}
getwd()
setwd(""C:/Users/changik/Desktop/ML school homework2/hw2-2"/Parking lot pics")
setwd(C:/Users/changik/Desktop/ML school homework2/hw2-2"/Parking lot pics")
setwd("C:/Users/changik/Desktop/ML school homework2/hw2-2"/Parking lot pics")
setwd?
?setwd()
train
load("C:/Users/changik/Google Drive/2016 Spring Semester/ML/ML school homework2/hw2-2/SavedWorkspace.RData")
dim(train)
dim(test)
n = ncol(train)
m = nrow(train)
train = cbind(rep(1,m), train)
n = ncol(train)
m = nrow(train)
initialTheta = matrix(0,n,1)    #set up initial theta
iters = 100;    #set iteration number
alpha = 0.01;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
source('logistic_header.R')
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = train %*% theta
dim(prediction)
prediction
prediction = sigmoid(train %*% theta)
prediction
prediction[prediction < 0.5] = 0
prediction[prediction >= 0.5] = 1
prediction
prediction = sigmoid(test %*% theta)
dim(test)
dim(theta)
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
dim(theta)
dim(train)
dim(test)
test = cbind(rep(1,m), test)
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
iters = 300;    #set iteration number
alpha = 0.1;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction < 0.5] = 0
prediction[prediction >= 0.5] = 1
which(prediction == testY)
length(which(prediction == testY))
length(which(prediction == testY)) / nrow(test)
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
source('~/Google Drive/2016 Spring Semester/ML/ML school homework2/hw2-2/ParkingLotClassifier.R')
install.packages("jpeg")
source('~/Google Drive/2016 Spring Semester/ML/ML school homework2/hw2-2/ParkingLotClassifier.R')
getwd()
source('~/Google Drive/2016 Spring Semester/ML/ML school homework2/hw2-2/ParkingLotClassifier.R')
rm(list=ls())
library(jpeg)
#setwd("./pics")
# ===== useful functions =====
col2gry <- function(img) { #720*1280 // to make it simple, we use gray scaled image
new_img = matrix(0,nrow=dim(img)[1],ncol=dim(img)[2])
for(i in 1:dim(img)[1]) {
for(j in 1:dim(img)[2]){
new_img[i,j]=sum(img[i,j,])/3
}
}
return (new_img)
}
subImage<-function(img,x1,y1,x2,y2) {
return (img[y2:y1,x1:x2])
}
# ===== data prep part =====
fs=list.files('.',pattern = '*.jpg')   #get a list of file name
yValue = c(0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,1,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,1,1,0,0,0,1,1,0,0,0,0,1,1,1,0,1,1,0,1,1,1,1,1,1,
0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,1,1,1,0,0,0,0,0)
dataList = matrix(0, nrow = 125, ncol = 1806)   #125 samples, 1806 feature
for(i in 1:length(fs)){   #get a subimage from each files
img = readJPEG(fs[i],native=FALSE)
gry=col2gry(img)
lot = subImage(gry,615,310,656,268) # location of selected lot
dataList[i, ] = lot
}
#data shuffle
set.seed(0)   #set seed for to generate same result in random sampling
randomIndex = sample(nrow(dataList))
train = dataList[randomIndex[1:125], ]
test = dataList[-randomIndex[1:125], ]
trainY = yValue[randomIndex[1:125]]
testY = yValue[-randomIndex[1:125]]
source('logistic_header.R')
train = cbind(rep(1,m), train)
test = cbind(rep(1,m), test)
n = ncol(train)
m = nrow(train)
initialTheta = matrix(0,n,1)    #set up initial theta
iters = 300;    #set iteration number
alpha = 0.1;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction < 0.5] = 0
prediction[prediction >= 0.5] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
iters = 300;    #set iteration number
alpha = 0.000001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction < 0.5] = 0
prediction[prediction >= 0.5] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
prediction
test
source('logistic_header.R')
train = cbind(rep(1,m), train)
test = cbind(rep(1,m), test)
n = ncol(train)
m = nrow(train)
train
test
set.seed(0)   #set seed for to generate same result in random sampling
randomIndex = sample(nrow(dataList))
train = dataList[randomIndex[1:100], ]
test = dataList[-randomIndex[100:125], ]
trainY = yValue[randomIndex[1:100],]
testY = yValue[-randomIndex[100:125],]
randomIndex
train = dataList[randomIndex[1:100, ]
test = dataList[-randomIndex[100:125, ]
trainY = yValue[randomIndex[1:100, ]
testY = yValue[-randomIndex[100:125, ]
randomIndex[1:100]
train = dataList[randomIndex[1:100], ]
test = dataList[-randomIndex[101:125], ]
trainY = yValue[randomIndex[1:100], ]
train = dataList[randomIndex[1:75], ]
test = dataList[-randomIndex[76:100], ]
trainY = yValue[randomIndex[1:75], ]
testY = yValue[-randomIndex[76:100, ]
dim(yValue)
yValue = c(0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,1,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,1,1,0,0,0,1,1,0,0,0,0,1,1,1,0,1,1,0,1,1,1,1,1,1,
0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,1,1,1,0,0,0,0,0)
randomIndex = sample(nrow(dataList))
train = dataList[randomIndex[1:100], ]
test = dataList[-randomIndex[101:125], ]
trainY = yValue[randomIndex[1:100], ]
testY = yValue[-randomIndex[101:125, ]
trainY = yValue[randomIndex[1:100]
testY = yValue[-randomIndex[101:125]
train = dataList[randomIndex[1:100], ]
test = dataList[-randomIndex[1:100], ]
trainY = yValue[randomIndex[1:100]]
testY = yValue[-randomIndex[1:100]]
train = cbind(rep(1,m), train)
test = cbind(rep(1,m), test)
n = ncol(train)
m = nrow(train)
initialTheta = matrix(0,n,1)    #set up initial theta
iters = 300;    #set iteration number
alpha = 0.000001;   #set alpha, running rate
testY
yValue = matrix(c(0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,1,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,1,1,0,0,0,1,1,0,0,0,0,1,1,1,0,1,1,0,1,1,1,1,1,1,
0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,1,1,1,0,0,0,0,0),
ncol =1)
trainY = yValue[randomIndex[1:100]], ]
testY = yValue[-randomIndex[1:100]], ]
View(yValue)
trainY = yValue[randomIndex[1:100], ]
testY = yValue[-randomIndex[1:100], ]
train = cbind(rep(1,m), train)
test = cbind(rep(1,m), test)
n = ncol(train)
m = nrow(train)
initialTheta = matrix(0,n,1)    #set up initial theta
iters = 300;    #set iteration number
alpha = 0.000001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction < 0.5] = 0
prediction[prediction >= 0.5] = 1
prediction
testY
train = cbind(rep(1,m), train)
test = cbind(rep(1,m), test)
n = ncol(train)
m = nrow(train)
initialTheta = matrix(0,n,1)    #set up initial theta
iters = 300;    #set iteration number
alpha = 0.000001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction
trainY
testY
prediction[prediction < 0.5] = 0
prediction[prediction >= 0.5] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
train %*% theta
sigmoid(train %*% theta)
yValue[which(yValue  == 0), ] = -1
yValue
prediction = sigmoid(test %*% theta)
prediction[prediction < 0] = -1
prediction[prediction >= 0] = 1
prediction
iters = 3000;    #set iteration number
alpha = 0.000001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction < 0] = -1
prediction[prediction >= 0] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
# ===== data prep part =====
fs=list.files('.',pattern = '*.jpg')   #get a list of file name
yValue = matrix(c(0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,1,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,1,1,0,0,0,1,1,0,0,0,0,1,1,1,0,1,1,0,1,1,1,1,1,1,
0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,1,1,1,0,0,0,0,0),
ncol =1)
dataList = matrix(0, nrow = 100, ncol = 1806)   #125 samples, 1806 feature
for(i in 1:length(fs)){   #get a subimage from each files
img = readJPEG(fs[i],native=FALSE)
gry=col2gry(img)
lot = subImage(gry,615,310,656,268) # location of selected lot
dataList[i, ] = lot
}
#data shuffle
set.seed(0)   #set seed for to generate same result in random sampling
randomIndex = sample(nrow(dataList))
train = dataList[randomIndex[1:100], ]
test = dataList[-randomIndex[1:100], ]
trainY = yValue[randomIndex[1:100], ]
testY = yValue[-randomIndex[1:100], ]
# ===== Classifier part =====
source('logistic_header.R')
train = cbind(rep(1,m), train)
test = cbind(rep(1,m), test)
n = ncol(train)
m = nrow(train)
initialTheta = matrix(0,n,1)    #set up initial theta
iters = 3000;    #set iteration number
alpha = 0.000001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction <  0.5] = 0
prediction[prediction >= 0.5] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
prediction
# ===== Classifier part =====
source('logistic_header.R')
train = cbind(rep(1,m), train)
test = cbind(rep(1,m), test)
n = ncol(train)
m = nrow(train)
initialTheta = matrix(0,n,1)    #set up initial theta
iters = 10;    #set iteration number
alpha = 0.000001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction <  0.5] = 0
prediction[prediction >= 0.5] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
source('logistic_header.R')
train = cbind(rep(1,m), train)
test = cbind(rep(1,m), test)
n = ncol(train)
m = nrow(train)
initialTheta = matrix(0,n,1)    #set up initial theta
iters = 10;    #set iteration number
alpha = 0.000001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
theta
prediction = sigmoid(test %*% theta)
prediction
test
train = dataList[randomIndex[1:100], ]
test = dataList[-randomIndex[1:100], ]
trainY = yValue[randomIndex[1:100], ]
testY = yValue[-randomIndex[1:100], ]
test
train
train = dataList[randomIndex[1:100], ]
test = dataList[-randomIndex[1:100], ]
test
train
randomIndex
dim(dataList)
rm(list=ls())
library(jpeg)
#setwd("./pics")
# ===== useful functions =====
col2gry <- function(img) { #720*1280 // to make it simple, we use gray scaled image
new_img = matrix(0,nrow=dim(img)[1],ncol=dim(img)[2])
for(i in 1:dim(img)[1]) {
for(j in 1:dim(img)[2]){
new_img[i,j]=sum(img[i,j,])/3
}
}
return (new_img)
}
subImage<-function(img,x1,y1,x2,y2) {
return (img[y2:y1,x1:x2])
}
# ===== data prep part =====
fs=list.files('.',pattern = '*.jpg')   #get a list of file name
yValue = matrix(c(0,0,0,0,0,1,1,1,1,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,1,1,1,1,0,0,1,0,0,0,0,0,0,0,
0,0,0,0,0,0,0,1,0,1,0,0,0,0,0,1,1,1,0,0,0,1,1,0,0,0,0,1,1,1,0,1,1,0,1,1,1,1,1,1,
0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,1,0,0,0,1,1,1,1,1,0,0,0,0,0),
ncol =1)
dataList = matrix(0, nrow = 125, ncol = 1806)   #125 samples, 1806 feature
for(i in 1:length(fs)){   #get a subimage from each files
img = readJPEG(fs[i],native=FALSE)
gry=col2gry(img)
lot = subImage(gry,615,310,656,268) # location of selected lot
dataList[i, ] = lot
}
#data shuffle
set.seed(0)   #set seed for to generate same result in random sampling
randomIndex = sample(nrow(dataList))
train = dataList[randomIndex[1:100], ]
test = dataList[-randomIndex[1:100], ]
trainY = yValue[randomIndex[1:100], ]
testY = yValue[-randomIndex[1:100], ]
testY
source('logistic_header.R')
train = cbind(rep(1,m), train)
test = cbind(rep(1,m), test)
n = ncol(train)
m = nrow(train)
initialTheta = matrix(0,n,1)    #set up initial theta
iters = 10;    #set iteration number
alpha = 0.000001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction <  0.5] = 0
prediction[prediction >= 0.5] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
initialTheta = matrix(0,n,1)    #set up initial theta
iters = 100;    #set iteration number
alpha = 0.000001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction <  0.5] = 0
prediction[prediction >= 0.5] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
iters = 100;    #set iteration number
alpha = 0.00001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction
dataList
dataList[1, ]
dataList[2, ]
dim(prediction)
iters = 100;    #set iteration number
alpha = 0.0001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction <  0.5] = 0
prediction[prediction >= 0.5] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
iters = 100;    #set iteration number
alpha = 0.001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction <  0.5] = 0
prediction[prediction >= 0.5] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
iters = 100;    #set iteration number
alpha = 0.01;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction <  0.5] = 0
prediction[prediction >= 0.5] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
iters = 300;    #set iteration number
alpha = 0.001;   #set alpha, running rate
theta = gradientDescent(train, trainY, initialTheta, alpha, iters);
prediction = sigmoid(test %*% theta)
prediction[prediction <  0.5] = 0
prediction[prediction >= 0.5] = 1
acc = length(which(prediction == testY)) / nrow(test)
print(paste0("Logistic Regression Classifier Accuracy is ", acc));
rm(list=ls())
library(jpeg)
source('logistic_header.R')
source('data_prep_header.R')
setwd("./images")
fs=list.files('.',pattern = '*.jpg')   #get a list of file name
dataList = matrix(0, nrow = 125, ncol = 1806)   #125 samples, 1806 feature
for(i in 1:length(fs)){   #get a subimage from each files
img = readJPEG(fs[i],native=FALSE)
gry=col2gry(img)
lot = subImage(gry,615,310,656,268) # location of selected lot
dataList[i, ] = lot
}
rm(list=ls())
library(jpeg)
source('logistic_header.R')
source('data_prep_header.R')
setwd("./images")
rm(list=ls())
library(jpeg)
source('logistic_header.R')
setwd(" ..")
getwd
getwd()
